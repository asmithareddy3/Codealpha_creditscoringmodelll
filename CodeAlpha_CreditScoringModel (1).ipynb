{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BX-vIqodjMba"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "data_csv = \"\"\"Income,Debts,PaymentHistory,Creditworthy\n",
        "50000,10000,Good,Yes\n",
        "40000,15000,Bad,No\n",
        "60000,20000,Good,Yes\n",
        "35000,18000,Bad,No\n",
        "80000,10000,Good,Yes\n",
        "45000,25000,Bad,No\n",
        "70000,12000,Good,Yes\n",
        "30000,28000,Bad,No\n",
        "65000,18000,Good,Yes\n",
        "42000,22000,Bad,No\n",
        "\"\"\"\n",
        "\n",
        "# Save as CSV\n",
        "with open(\"credit_data.csv\", \"w\") as f:\n",
        "    f.write(data_csv)\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"credit_data.csv\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "oaCDKJU7lHj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f52fd85-33f0-451b-c61f-49a6fe806e90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Income  Debts PaymentHistory Creditworthy\n",
            "0   50000  10000           Good          Yes\n",
            "1   40000  15000            Bad           No\n",
            "2   60000  20000           Good          Yes\n",
            "3   35000  18000            Bad           No\n",
            "4   80000  10000           Good          Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical data\n",
        "le = LabelEncoder()\n",
        "data[\"PaymentHistory\"] = le.fit_transform(data[\"PaymentHistory\"])\n",
        "data[\"Creditworthy\"] = le.fit_transform(data[\"Creditworthy\"])\n",
        "\n",
        "# Features and Target\n",
        "X = data.drop(\"Creditworthy\", axis=1)\n",
        "y = data[\"Creditworthy\"]\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "EbAlf6jMldo0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "    print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "nTsLEmtZlkWB",
        "outputId": "4aab17a1-6309-4c36-8a87-c8ec20d5fd0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Results:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "ROC-AUC: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "ROC-AUC: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "ROC-AUC: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZb1dNrPyU8x"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}